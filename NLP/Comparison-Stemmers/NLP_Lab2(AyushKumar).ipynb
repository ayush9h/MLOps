{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gWY9388aZgKH",
        "outputId": "3fc4a52f-9c63-463c-f376-951205fd3a78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing stemmer libraries"
      ],
      "metadata": {
        "id": "ilOfu0VQaRAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from nltk.stem.lancaster import LancasterStemmer"
      ],
      "metadata": {
        "id": "F3kkx9CmZ2ZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "td4fGhyBbZ_V",
        "outputId": "4300fae9-9799-4732-8703-7c644a765f2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining Inputs"
      ],
      "metadata": {
        "id": "1MXadwEbguVm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_sentences = [\n",
        "    \"professor lectures were renowned for their profundity often delving into abstruse topics\",\n",
        "    \"tempestuous relationship between two lovers was fraught with acrimony and recrimination\",\n",
        "    \"enigmatic manuscript discovered dusty attic contained cryptic symbols that defied interpretation\",\n",
        "    \"arcane rituals performed indigenous tribe during equinox were shrouded mystery and intrigue\",\n",
        "    \"hermit lived reclusive life hinterlands surrounded arcane artifacts and ancient texts\"\n",
        "]"
      ],
      "metadata": {
        "id": "7TAqQW0ogxDE"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_sentences = [word_tokenize(sentence) for sentence in input_sentences]"
      ],
      "metadata": {
        "id": "eXs2FTA1Z43H"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparison of Stemmers"
      ],
      "metadata": {
        "id": "xZYRcu1VeJGJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "porter_stemmer = PorterStemmer()\n",
        "snowball_stemmer = SnowballStemmer(language='english')\n",
        "lancaster_stemmer = LancasterStemmer()\n",
        "\n",
        "stemmed_porter = [[porter_stemmer.stem(word) for word in tokenized_sentence] for tokenized_sentence in tokenized_sentences]\n",
        "stemmed_snowball = [[snowball_stemmer.stem(word) for word in tokenized_sentence] for tokenized_sentence in tokenized_sentences]\n",
        "stemmed_lancaster = [[lancaster_stemmer.stem(word) for word in tokenized_sentence] for tokenized_sentence in tokenized_sentences]"
      ],
      "metadata": {
        "id": "6Qrj7l-bbXmr"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Using Porter Stemmer: \")\n",
        "for index, stemmed_sentence in enumerate(stemmed_porter, 1):\n",
        "    print(f\"Sentence {index}: {stemmed_sentence}\")\n",
        "\n",
        "print(\"Using Snowball Stemmer: \")\n",
        "for index, stemmed_sentence in enumerate(stemmed_snowball, 1):\n",
        "    print(f\"Sentence {index}: {stemmed_sentence}\")\n",
        "\n",
        "print(\"Using Lancaster Stemmer: \")\n",
        "for index, stemmed_sentence in enumerate(stemmed_lancaster, 1):\n",
        "    print(f\"Sentence {index}: {stemmed_sentence}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnrEft00pyiY",
        "outputId": "411806cb-49c4-41b0-dd4b-4e3ecb98e665"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Porter Stemmer: \n",
            "Sentence 1: ['professor', 'lectur', 'were', 'renown', 'for', 'their', 'profund', 'often', 'delv', 'into', 'abstrus', 'topic']\n",
            "Sentence 2: ['tempestu', 'relationship', 'between', 'two', 'lover', 'wa', 'fraught', 'with', 'acrimoni', 'and', 'recrimin']\n",
            "Sentence 3: ['enigmat', 'manuscript', 'discov', 'dusti', 'attic', 'contain', 'cryptic', 'symbol', 'that', 'defi', 'interpret']\n",
            "Sentence 4: ['arcan', 'ritual', 'perform', 'indigen', 'tribe', 'dure', 'equinox', 'were', 'shroud', 'mysteri', 'and', 'intrigu']\n",
            "Sentence 5: ['hermit', 'live', 'reclus', 'life', 'hinterland', 'surround', 'arcan', 'artifact', 'and', 'ancient', 'text']\n",
            "Using Snowball Stemmer: \n",
            "Sentence 1: ['professor', 'lectur', 'were', 'renown', 'for', 'their', 'profund', 'often', 'delv', 'into', 'abstrus', 'topic']\n",
            "Sentence 2: ['tempestu', 'relationship', 'between', 'two', 'lover', 'was', 'fraught', 'with', 'acrimoni', 'and', 'recrimin']\n",
            "Sentence 3: ['enigmat', 'manuscript', 'discov', 'dusti', 'attic', 'contain', 'cryptic', 'symbol', 'that', 'defi', 'interpret']\n",
            "Sentence 4: ['arcan', 'ritual', 'perform', 'indigen', 'tribe', 'dure', 'equinox', 'were', 'shroud', 'mysteri', 'and', 'intrigu']\n",
            "Sentence 5: ['hermit', 'live', 'reclus', 'life', 'hinterland', 'surround', 'arcan', 'artifact', 'and', 'ancient', 'text']\n",
            "Using Lancaster Stemmer: \n",
            "Sentence 1: ['profess', 'lect', 'wer', 'renown', 'for', 'their', 'profund', 'oft', 'delv', 'into', 'abstrus', 'top']\n",
            "Sentence 2: ['tempestu', 'rel', 'between', 'two', 'lov', 'was', 'fraught', 'with', 'acrimony', 'and', 'recrimin']\n",
            "Sentence 3: ['enigm', 'manuscrib', 'discov', 'dusty', 'at', 'contain', 'crypt', 'symbol', 'that', 'defy', 'interpret']\n",
            "Sentence 4: ['arc', 'rit', 'perform', 'indig', 'trib', 'dur', 'equinox', 'wer', 'shrouded', 'mystery', 'and', 'intrigu']\n",
            "Sentence 5: ['hermit', 'liv', 'reclud', 'lif', 'hinterland', 'surround', 'arc', 'artifact', 'and', 'ant', 'text']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Applying Lemmatization"
      ],
      "metadata": {
        "id": "djL-rqxjehyu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCFBbTEdb_SR",
        "outputId": "b62ca7bc-6a6e-43f0-ed17-acfb7028fd9a"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "lemmatized_sentence = [[lemmatizer.lemmatize(word) for word in tokenized_sentence] for tokenized_sentence in tokenized_sentences]"
      ],
      "metadata": {
        "id": "TENyHluBezFw"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Using WordNet Lemmatization: \")\n",
        "for i,lemmatize_sentence in enumerate(lemmatized_sentence,1):\n",
        "  print(f\"Sentence {i}: {lemmatize_sentence}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNyuPFWwre9F",
        "outputId": "c81e3dbc-dd64-43ed-90da-f398689ed1aa"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using WordNet Lemmatization: \n",
            "Sentence 1: ['professor', 'lecture', 'were', 'renowned', 'for', 'their', 'profundity', 'often', 'delving', 'into', 'abstruse', 'topic']\n",
            "Sentence 2: ['tempestuous', 'relationship', 'between', 'two', 'lover', 'wa', 'fraught', 'with', 'acrimony', 'and', 'recrimination']\n",
            "Sentence 3: ['enigmatic', 'manuscript', 'discovered', 'dusty', 'attic', 'contained', 'cryptic', 'symbol', 'that', 'defied', 'interpretation']\n",
            "Sentence 4: ['arcane', 'ritual', 'performed', 'indigenous', 'tribe', 'during', 'equinox', 'were', 'shrouded', 'mystery', 'and', 'intrigue']\n",
            "Sentence 5: ['hermit', 'lived', 'reclusive', 'life', 'hinterland', 'surrounded', 'arcane', 'artifact', 'and', 'ancient', 'text']\n"
          ]
        }
      ]
    }
  ]
}